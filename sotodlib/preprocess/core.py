"""Base Class and PIPELINE register for the preprocessing pipeline scripts."""
import logging
import numpy as np
from .. import core
from so3g.proj import RangesMatrix

class _Preprocess(object):
    """The base class for Preprocessing modules which defines the required
    functions and keys required in the configurations.

    Each preprocess module has four overwritable functions that are called by
    the processing scripts in site_pipeline. These four functions are each
    controlled by a specific key in a configuration dictionary passed to the
    module on creation.

    The configuration dictionary has 5 special keys: ``name``, ``process``,
    ``calc``, ``save``, and ``select``. ``name`` is the name used to register 
    the module with the PIPELINE registry. The other four keys are matched to 
    functions in the module, if the key is not present then that function will 
    be skipped when the preprocessing pipeline is run.

    There are two special AxisManagers expected to be part of the preprocessing
    pipeline. ``aman`` is the "standard" time ordered data AxisManager that is
    loaded via our default styles. ``proc_aman`` is the preprocess AxisManager,
    this is carry the data products that will be saved to whatever Metadata
    Archive is connected to the preprocessing pipeline. 
    """    

    def __init__(self, step_cfgs):
        self.process_cfgs = step_cfgs.get("process")
        self.calc_cfgs = step_cfgs.get("calc")
        self.save_cfgs = step_cfgs.get("save")
        self.select_cfgs = step_cfgs.get("select")
    
    def process(self, aman, proc_aman):
        """ This function makes changes to the time ordered data AxisManager.
        Ex: calibrating or detrending the timestreams. This function will use
        any configuration information under the ``process`` key of the
        configuration dictionary and is not expected to change or alter
        proc_aman.


        Arguments
        ---------
        aman : AxisManager 
            The time ordered data
        proc_aman : AxisManager 
            Any information generated by previous elements in the preprocessing 
            pipeline.
        """
        if self.process_cfgs is None:
            return
        raise NotImplementedError
        
    def calc_and_save(self, aman, proc_aman):
        """ This function calculates data products of some sort off of the time
        ordered data AxisManager.

        Ex: Calcuating the white noise of the timestream. This function will use
        any configuration information under the ``calc`` key of the
        configuration dictionary and can call the save function to make
        changes to proc_aman.

        Arguments
        ---------
        aman : AxisManager 
            The time ordered data
        proc_aman : AxisManager 
            Any information generated by previous elements in the preprocessing 
            pipeline.
        """
        if self.calc_cfgs is None:
            return
        raise NotImplementedError
    
    def save(self, proc_aman, *args):
        """ This function wraps new information into the proc_aman and will use
        any configuration information under the ``save`` key of the
        configuration dictionary.

        Arguments
        ---------
        proc_aman : AxisManager 
            Any information generated by previous elements in the preprocessing 
            pipeline.
        args : any
            Any additional information ``calc_and_save`` needs to send to the
            save function.
        """
        if self.save_cfgs is None:
            return
        raise NotImplementedError
        
    def select(self, meta, proc_aman=None):
        """ This function runs any desired data selection of the preprocessing
        pipeline results. Assumes the pipeline has already been run and that the
        resulting proc_aman is now saved under the ``preprocess`` key in the
        ``meta`` AxisManager loaded via context.

        Ex: removing detectors with white noise above some limit. This function will use
        any configuration information under the ``select`` key.


        Arguments
        ---------
        meta : AxisManager 
            Metadata related to the specific observation

        Returns
        -------
        meta : AxisManager 
            Metadata where non-selected detectors have been removed
        """

        if self.select_cfgs is None:
            return meta
        raise NotImplementedError
    
    @staticmethod
    def register(process_class):
        """Registers a new modules with the PIPELINE"""
        name = process_class.name

        if Pipeline.PIPELINE.get(name) is None:
            Pipeline.PIPELINE[name] = process_class
        else:
            raise ValueError(
                f"Preprocess Module of name {name} is already Registered"
            )

def expand_proc_aman(calc_aman, proc_aman, flag_fill_val=False,
                     flt_fill_val=np.nan, int_fill_val=2**32-1):
    """
    Helper function to expand the size of calculated products to match the 
    precut dets and samps shape.
    Arguments:
    ----------
    calc_aman: AxisManager
        AxisManager returned from calc step.
    proc_aman: AxisManager
        AxisManager passed between processes.
    fill_value:
        Value to fill missing indices with.
    """
    if (proc_aman.dets.count < proc_aman.fdets.count) or \
       (proc_aman.samps.count < proc_aman.fsamps.count):
        _, mdets, fmdets = np.intersect1d(proc_aman.dets.vals,
                                          proc_aman.fdets.vals,
                                          return_indices=True)
        fmsamps = slice(proc_aman.samps.offset,
                        proc_aman.samps.offset+proc_aman.samps.count)
    
    out_aman = core.AxisManager(proc_aman.fdets, proc_aman.fsamps)
    for fld in calc_aman._fields:
        dat = calc_aman[fld]
        dax, sax = None, None
        axes = calc_aman.shape_str(fld).split(',')
        maxes = np.isin(axes, ['dets', 'samps'])
        axismap = [(i, a) for i, a in enumerate(axes)]
        faxismap = [(i, 'f'+a) if m else (i, a) for i, [a, m] in enumerate(list(zip(axes, maxes)))]
        if np.all(~maxes):
            out_aman.wrap(fld, dat, axismap)
        else:
            if np.isin(type(np.hstack(dat)[0]), [so3g.RangesInt32, bool]):
                fill_value = flag_fill_val
                if isinstance(dat, RangesMatrix):
                    dat = dat.mask()
            if np.isin(type(np.hstack(dat)[0]), [np.int64, np.int32, int]):
                fill_value = int_fill_val
            if np.isin(type(np.hstack(dat)[0]), [np.float64, np.float32, float]):
                fill_value = flt_fill_val

            shape = tuple([proc_aman[am].count if m else calc_aman[fld].count for am, m in zip(axismap, maxes)])
            fdat = np.full(shape, fill_value)

            if ('dets' in axes) and not('samps' in axes):
                dax = np.where(axes == 'dets')[0]
                dat = np.moveaxis(dat, dax, 0)
                fdat = np.moveaxis(fdat, dax, 0) 
                fdat[fmdets] = dat
                dat = np.moveaxis(dat, 0, dax)
                fdat = np.moveaxis(fdat, 0, dax)
            elif ('samps' in axes) and not('dets' in axes):
                sax = np.where(axes == 'samps')[0]
                dat = np.moveaxis(dat, sax, 0)
                fdat = np.moveaxis(fdat, sax, 0)
                fdat[fmsamps] = dat
                dat = np.moveaxis(dat, 0, sax)
                fdat = np.moveaxis(fdat, 0, sax)
            else:
                dax = np.where(axes == 'dets')[0]
                sax = np.where(axes == 'samps')[0]
                dat = np.moveaxis(dat, (dax, sax), (0,1))
                fdat = np.moveaxis(fdat, (dax, sax), (0,1))
                fdat[fmdets, fmsamps] = dat
                dat = np.moveaxis(dat, (0,1), dax, sax)
                fdat = np.moveaxis(fdat, (0,1), (dax, sax))
            
            if isinstance(fill_value, bool):
                fdat = RangesMatrix.from_mask(fdat)
                dat = RangesMatrix.from_mask(dat)
            out_aman.wrap(fld, dat, axismap)
            out_aman.wrap(fld, fdat, faxismap)

class Pipeline(list):
    """This class is designed to create and run pipelines out of a series of
    different preprocessing modules (classes that inherent from _Preprocess). It
    inherits list object. It also contains the registration of all possible
    preprocess modules in Pipeline.PIPELINE
    """

    PIPELINE = {}

    def __init__(self, modules, logger=None):
        """
        Arguments
        ---------
        modules: iterable
            A list or other iterable that contains either instantiated
            _Preprocess instances or the configuration dictionary used to
            instantiate a module
        logger: optional
            logging.logger instance used by the pipeline to send updates
        """
        if logger is None:
            logger = logging.getLogger("pipeline")
        self.logger = logger
        super().__init__( [self._check_item(item) for item in modules])
    
    def _check_item(self, item):
        if isinstance(item, _Preprocess):
            return item
        elif isinstance(item, dict):
            name = item.get("name")
            if name is None:
                raise ValueError(f"Processes made from dictionary must have a 'name' key")
            cls = self.PIPELINE.get(name)
            if cls is None:
                raise ValueError(f"'{name}' not registered as a pipeline element")
            return cls(item)
        else:
            raise ValueError(f"Unknown type created a pipeline element")
    
    # make pipeline have all the list pieces
    def append(self, item):
        super().append( self._check_item(item) )
    def insert(self, index, item):
        super().insert(index, self._check_item(item))
    def extend(self, index, other):
        if isinstance(other, type(self)):
            super().extend(other)
        else:
            super().extend( [self._check_item(item) for item in other])
    def __setitem__(self, index, item):
        super().__setitem__(index, self._check_item(item))
    
    def run(self, aman, proc_aman=None, select=True):
        """
        The main workhorse function for the pipeline class. This function takes
        an AxisManager TOD and successively runs the pipeline of preprocessing
        modules on the AxisManager. The order of operations called by run are::

            for process in pipeline:
                process.process()
                process.calc_and_save()
                    process.save() ## called by process.calc_and_save()
                process.select()

        Arguments
        ---------
        aman: AxisManager
            A TOD object. Generally expected to be raw, unprocessed data. This
            axismanager will be edited in place by the process and select
            functions of each preprocess module
        proc_aman: AxisManager (Optional)
            A preprocess axismanager. If this is provided it is assumed that the
            pipeline has previously been run on this specific TOD and has
            returned this preprocess axismanager. In this case, calls to
            ``process.calc_and_save()`` are skipped as the information is
            expected to be present in this AxisManager.
        select: boolean (Optional)
            if True, the aman detector axis is restricted as described in
            each preprocess module

        Returns
        -------
        proc_aman: AxisManager
            A preprocess axismanager that contains all data products calculated
            throughout the running of the pipeline
        
        """
        if proc_aman is None:
            proc_aman = core.AxisManager( aman.dets, aman.samps)
            fman = core.AxisManager(core.LabelAxis(name='fdets', vals=aman.dets.vals), 
                                    core.OffsetAxis('fsamps', count=aman.samps.count,
                                                    offset=aman.samps.offset, 
                                                    origin_tag=aman.samps.origin_tag))
            proc_aman.merge(fman)
            run_calc = True
        else:
            if aman.dets.count != proc_aman.dets.count or not np.all(aman.dets.vals == proc_aman.dets.vals):
                self.logger.warning("proc_aman has different detectors than aman. Cutting aman to match")
                det_list = [det for det in proc_aman.dets.vals if det in aman.dets.vals]
                aman.restrict('dets', det_list)
                proc_aman.restrict('dets', det_list)
            run_calc = False
            
        for process in self:
            self.logger.info(f"Running {process.name}")
            process.process(aman, proc_aman)
            if run_calc:
                process.calc_and_save(aman, proc_aman)
            if select:
                process.select(aman, proc_aman)
                proc_aman.restrict('dets', aman.dets.vals)
        return proc_aman
